{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc76ced2",
   "metadata": {},
   "source": [
    "### Json Parsing And Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf84111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.makedirs(\"data/json_files\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c260a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample nested JSON data\n",
    "json_data = {\n",
    "    \"company\": \"TechCorp\",\n",
    "    \"employees\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"John Doe\",\n",
    "            \"role\": \"Software Engineer\",\n",
    "            \"skills\": [\"Python\", \"JavaScript\", \"React\"],\n",
    "            \"projects\": [\n",
    "                {\"name\": \"RAG System\", \"status\": \"In Progress\"},\n",
    "                {\"name\": \"Data Pipeline\", \"status\": \"Completed\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"Jane Smith\",\n",
    "            \"role\": \"Data Scientist\",\n",
    "            \"skills\": [\"Python\", \"Machine Learning\", \"SQL\"],\n",
    "            \"projects\": [\n",
    "                {\"name\": \"ML Model\", \"status\": \"In Progress\"},\n",
    "                {\"name\": \"Analytics Dashboard\", \"status\": \"Planning\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"departments\": {\n",
    "        \"engineering\": {\n",
    "            \"head\": \"Mike Johnson\",\n",
    "            \"budget\": 1000000,\n",
    "            \"team_size\": 25\n",
    "        },\n",
    "        \"data_science\": {\n",
    "            \"head\": \"Sarah Williams\",\n",
    "            \"budget\": 750000,\n",
    "            \"team_size\": 15\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a48f34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 'TechCorp',\n",
       " 'employees': [{'id': 1,\n",
       "   'name': 'John Doe',\n",
       "   'role': 'Software Engineer',\n",
       "   'skills': ['Python', 'JavaScript', 'React'],\n",
       "   'projects': [{'name': 'RAG System', 'status': 'In Progress'},\n",
       "    {'name': 'Data Pipeline', 'status': 'Completed'}]},\n",
       "  {'id': 2,\n",
       "   'name': 'Jane Smith',\n",
       "   'role': 'Data Scientist',\n",
       "   'skills': ['Python', 'Machine Learning', 'SQL'],\n",
       "   'projects': [{'name': 'ML Model', 'status': 'In Progress'},\n",
       "    {'name': 'Analytics Dashboard', 'status': 'Planning'}]}],\n",
       " 'departments': {'engineering': {'head': 'Mike Johnson',\n",
       "   'budget': 1000000,\n",
       "   'team_size': 25},\n",
       "  'data_science': {'head': 'Sarah Williams',\n",
       "   'budget': 750000,\n",
       "   'team_size': 15}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ecc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/json_files/company_data.json', 'w') as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e89f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON Lines format\n",
    "jsonl_data = [\n",
    "    {\"timestamp\": \"2024-01-01\", \"event\": \"user_login\", \"user_id\": 123},\n",
    "    {\"timestamp\": \"2024-01-01\", \"event\": \"page_view\", \"user_id\": 123, \"page\": \"/home\"},\n",
    "    {\"timestamp\": \"2024-01-01\", \"event\": \"purchase\", \"user_id\": 123, \"amount\": 99.99}\n",
    "]\n",
    "\n",
    "with open('data/json_files/events.jsonl', 'w') as f:\n",
    "    for item in jsonl_data:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be462888",
   "metadata": {},
   "source": [
    "## Json Processing Stratergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a1f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1️⃣ JSONLoader - Extract specific fields\n",
      "Loaded 2 employee documents\n",
      "First employee: {\"id\": 1, \"name\": \"John Doe\", \"role\": \"Software Engineer\", \"skills\": [\"Python\", \"JavaScript\", \"React\"], \"projects\": [{\"name\": \"RAG System\", \"status\": \"In Progress\"}, {\"name\": \"Data Pipeline\", \"status\"...\n",
      "[Document(metadata={'source': 'C:\\\\Data_Science\\\\RAG\\\\Project\\\\DataIngestParsing\\\\data\\\\json_files\\\\company_data.json', 'seq_num': 1}, page_content='{\"id\": 1, \"name\": \"John Doe\", \"role\": \"Software Engineer\", \"skills\": [\"Python\", \"JavaScript\", \"React\"], \"projects\": [{\"name\": \"RAG System\", \"status\": \"In Progress\"}, {\"name\": \"Data Pipeline\", \"status\": \"Completed\"}]}'), Document(metadata={'source': 'C:\\\\Data_Science\\\\RAG\\\\Project\\\\DataIngestParsing\\\\data\\\\json_files\\\\company_data.json', 'seq_num': 2}, page_content='{\"id\": 2, \"name\": \"Jane Smith\", \"role\": \"Data Scientist\", \"skills\": [\"Python\", \"Machine Learning\", \"SQL\"], \"projects\": [{\"name\": \"ML Model\", \"status\": \"In Progress\"}, {\"name\": \"Analytics Dashboard\", \"status\": \"Planning\"}]}')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "import json\n",
    "\n",
    "## MEthod1 : JsonLoader With jq_schema\n",
    "print(\"1️⃣ JSONLoader - Extract specific fields\")\n",
    "\n",
    "# Extract employee information\n",
    "employee_loader = JSONLoader(\n",
    "    file_path='data/json_files/company_data.json',\n",
    "    jq_schema='.employees[]',  # jq query to extract each employee\n",
    "    text_content=False  # Get full JSON objects\n",
    ")\n",
    "\n",
    "employee_docs = employee_loader.load()\n",
    "print(f\"Loaded {len(employee_docs)} employee documents\")\n",
    "print(f\"First employee: {employee_docs[0].page_content[:200]}...\")\n",
    "print(employee_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecf851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc3f672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "Built 100 documents (manual).\n",
      "{\"userId\": 1, \"id\": 1, \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\", \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit ...\n",
      "Sample metadata: {'source': 'https://jsonplaceholder.typicode.com/posts', 'seq_num': 0, 'id': 1}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Try to import Document from common places — flexible for different langchain versions\n",
    "try:\n",
    "    from langchain_core.documents import Document\n",
    "except Exception:\n",
    "    try:\n",
    "        from langsmith.schemas import Document\n",
    "    except Exception:\n",
    "        # Final fallback: create a simple Document-like dict if import fails\n",
    "        Document = None\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"DemoScript/1.0\"\n",
    "HEADERS = {\"User-Agent\": os.environ[\"USER_AGENT\"]}\n",
    "URL = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "\n",
    "def fetch_and_build_documents(url: str):\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    docs = []\n",
    "    for i, item in enumerate(data):\n",
    "        text = json.dumps(item, ensure_ascii=False)  # store JSON as readable text\n",
    "        meta = {\"source\": url, \"seq_num\": i, \"id\": item.get(\"id\")}\n",
    "        if Document is None:\n",
    "            # fallback: create simple dict-like document\n",
    "            docs.append({\"page_content\": text, \"metadata\": meta})\n",
    "        else:\n",
    "            docs.append(Document(page_content=text, metadata=meta))\n",
    "    return docs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    docs = fetch_and_build_documents(URL)\n",
    "    print(type(docs[0]))\n",
    "    print(f\"Built {len(docs)} documents (manual).\")\n",
    "    # Printing preview safely in case the Document is a dict fallback\n",
    "    preview = docs[0].page_content if hasattr(docs[0], \"page_content\") else docs[0][\"page_content\"]\n",
    "    print(preview[:200], \"...\")\n",
    "    print(\"Sample metadata:\", (docs[0].metadata if hasattr(docs[0], \"metadata\") else docs[0][\"metadata\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ef19a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2️⃣ Custom JSON Processing\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Custom JSON processing for complex structures\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "print(\"\\n2️⃣ Custom JSON Processing\")\n",
    "\n",
    "def process_json_intelligently(filepath: str) -> List[Document]:\n",
    "    \"\"\"Process JSON with intelligent flattening and context preservation\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    # Strategy 1: Create documents for each employee with full context\n",
    "    for emp in data.get('employees', []):\n",
    "        content = f\"\"\"Employee Profile:\n",
    "        Name: {emp['name']}\n",
    "        Role: {emp['role']}\n",
    "        Skills: {', '.join(emp['skills'])}\n",
    "\n",
    "        Projects:\"\"\"\n",
    "        for proj in emp.get('projects', []):\n",
    "            content += f\"\\n- {proj['name']} (Status: {proj['status']})\"\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                'source': filepath,\n",
    "                'data_type': 'employee_profile',\n",
    "                'employee_id': emp['id'],\n",
    "                'employee_name': emp['name'],\n",
    "                'role': emp['role']\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b3b7c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/json_files/company_data.json', 'data_type': 'employee_profile', 'employee_id': 1, 'employee_name': 'John Doe', 'role': 'Software Engineer'}, page_content='Employee Profile:\\n        Name: John Doe\\n        Role: Software Engineer\\n        Skills: Python, JavaScript, React\\n\\n        Projects:\\n- RAG System (Status: In Progress)\\n- Data Pipeline (Status: Completed)'),\n",
       " Document(metadata={'source': 'data/json_files/company_data.json', 'data_type': 'employee_profile', 'employee_id': 2, 'employee_name': 'Jane Smith', 'role': 'Data Scientist'}, page_content='Employee Profile:\\n        Name: Jane Smith\\n        Role: Data Scientist\\n        Skills: Python, Machine Learning, SQL\\n\\n        Projects:\\n- ML Model (Status: In Progress)\\n- Analytics Dashboard (Status: Planning)')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_json_intelligently(\"data/json_files/company_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac127c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
